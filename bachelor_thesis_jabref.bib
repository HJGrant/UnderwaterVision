@Misc{smolyanskiy2020importance,
  author        = {Nikolai Smolyanskiy and Alexey Kamenev and Stan Birchfield},
  title         = {On the Importance of Stereo for Accurate Depth Estimation: An Efficient Semi-Supervised Deep Neural Network Approach},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1803.09719},
  groups        = {Depth Maps},
  primaryclass  = {cs.CV},
  ranking       = {rank3},
  readstatus    = {skimmed},
}

@Misc{liu2019neural,
  author        = {Chao Liu and Jinwei Gu and Kihwan Kim and Srinivasa Narasimhan and Jan Kautz},
  title         = {Neural RGB->D Sensing: Depth and Uncertainty from a Video Camera},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1901.02571},
  groups        = {Depth Maps},
  primaryclass  = {cs.CV},
  ranking       = {rank1},
  readstatus    = {skimmed},
}

@InProceedings{10.1145/3567600.3568158,
  author    = {Wong, Emily and Humphrey, Isabella and Switzer, Scott and Crutchfield, Christopher and Hui, Nathan and Schurgers, Curt and Kastner, Ryan},
  booktitle = {Proceedings of the 16th International Conference on Underwater Networks \& Systems},
  title     = {Underwater Depth Calibration Using a Commercial Depth Camera},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {WUWNet '22},
  abstract  = {Depth cameras are increasingly used in research and industry in underwater settings. However, cameras that have been calibrated in air are notably inaccurate in depth measurements when placed underwater, and little research has been done to explore pre-existing depth calibration methodologies and their effectiveness in underwater environments. We used four methods of calibration on a low-cost, commercial depth camera both in and out of water. For each of these methods, we compared the predicted distance and length of objects from the camera with manually measured values to get an indication of depth and length accuracy. Our findings indicate that the standard methods of calibration in air are largely ineffective for underwater calibration and that custom calibration techniques are necessary to achieve higher accuracy.},
  articleno = {22},
  doi       = {10.1145/3567600.3568158},
  groups    = {Camera Calibration},
  isbn      = {9781450399524},
  keywords  = {Underwater stereo vision, depth camera calibration},
  location  = {Boston, MA, USA},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3567600.3568158},
}

@InProceedings{Hirschmuller,
  author    = {Hirschmuller, H.},
  booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPRâ€™05)},
  title     = {Accurate and Efficient Stereo Processing by Semi-Global Matching and Mutual Information},
  publisher = {IEEE},
  doi       = {10.1109/cvpr.2005.56},
  priority  = {prio3},
}

@InProceedings{Akkaynak2019,
  author    = {Akkaynak, Derya and Treibitz, Tali},
  booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Sea-Thru: A Method for Removing Water From Underwater Images},
  year      = {2019},
  month     = jun,
  publisher = {IEEE},
  doi       = {10.1109/cvpr.2019.00178},
  groups    = {Underwater Environment},
}

@InProceedings{Swirski2009,
  author    = {Swirski, Yohay and Schechner, Yoav Y and Herzberg, Ben and Negahdaripour, Shahriar},
  booktitle = {2009 IEEE 12th International Conference on Computer Vision},
  title     = {Stereo from flickering caustics},
  year      = {2009},
  month     = sep,
  publisher = {IEEE},
  doi       = {10.1109/iccv.2009.5459166},
  groups    = {Underwater Environment},
}

@Article{Hu2023,
  author     = {Hu, Kai and Wang, Tianyan and Shen, Chaowen and Weng, Chenghang and Zhou, Fenghua and Xia, Min and Weng, Liguo},
  journal    = {Journal of Marine Science and Engineering},
  title      = {Overview of Underwater 3D Reconstruction Technology Based on Optical Images},
  year       = {2023},
  issn       = {2077-1312},
  month      = apr,
  number     = {5},
  pages      = {949},
  volume     = {11},
  doi        = {10.3390/jmse11050949},
  groups     = {Underwater 3D Reconstruction},
  publisher  = {MDPI AG},
  ranking    = {rank3},
  readstatus = {read},
}

@InProceedings{Beall2010,
  author    = {Beall, C and Lawrence, B J and Ila, V and Dellaert, F},
  booktitle = {2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {3D reconstruction of underwater structures},
  year      = {2010},
  month     = oct,
  publisher = {IEEE},
  doi       = {10.1109/iros.2010.5649213},
  groups    = {Underwater 3D Reconstruction},
}

@Article{Zhuang2020,
  author    = {Zhuang, Sufeng and Zhang, Xu and Tu, Dawei and Zhang, Can and Xie, Liangliang},
  journal   = {Measurement Science and Technology},
  title     = {A standard expression of underwater binocular vision for stereo matching},
  year      = {2020},
  issn      = {1361-6501},
  month     = sep,
  number    = {11},
  pages     = {115012},
  volume    = {31},
  doi       = {10.1088/1361-6501/ab94fd},
  publisher = {IOP Publishing},
}

@Article{Huo2018,
  author    = {Huo, Guanying and Wu, Ziyin and Li, Jiabiao and Li, Shoujun},
  journal   = {Sensors},
  title     = {Underwater Target Detection and 3D Reconstruction System Based on Binocular Vision},
  year      = {2018},
  issn      = {1424-8220},
  month     = oct,
  number    = {10},
  pages     = {3570},
  volume    = {18},
  doi       = {10.3390/s18103570},
  groups    = {Underwater 3D Reconstruction},
  priority  = {prio1},
  publisher = {MDPI AG},
}

@InProceedings{Wang2019,
  author    = {Wang, Cong and Zhang, Qifeng and Lin, Sen and Li, Wentao and Wang, Xiaohui and Bai, Yunfei and Tian, Qiyan},
  booktitle = {OCEANS 2019 - Marseille},
  title     = {Research and Experiment of an Underwater Stereo Vision System},
  year      = {2019},
  month     = jun,
  publisher = {IEEE},
  doi       = {10.1109/oceanse.2019.8867236},
}

@InProceedings{Oleari2015,
  author     = {Oleari, Fabio and Kallasi, Fabjan and Rizzini, Dario Lodi and Aleotti, Jacopo and Caselli, Stefano},
  booktitle  = {OCEANS 2015 - Genova},
  title      = {An underwater stereo vision system: From design to deployment and dataset acquisition},
  year       = {2015},
  month      = may,
  publisher  = {IEEE},
  doi        = {10.1109/oceans-genova.2015.7271529},
  groups     = {Hardware},
  priority   = {prio3},
  readstatus = {skimmed},
}

@Misc{Chang2022,
  author    = {Chang, Qiong and Maruyama, Tsutomu},
  title     = {Real-Time High-Quality Stereo Matching System on a GPU},
  year      = {2022},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.48550/ARXIV.2212.00488},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Badki2020,
  author     = {Badki, Abhishek and Troccoli, Alejandro and Kim, Kihwan and Kautz, Jan and Sen, Pradeep and Gallo, Orazio},
  title      = {Bi3D: Stereo Depth Estimation via Binary Classifications},
  year       = {2020},
  copyright  = {arXiv.org perpetual, non-exclusive license},
  doi        = {10.48550/ARXIV.2005.07274},
  keywords   = {Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher  = {arXiv},
  readstatus = {skimmed},
}

 
@Article{Ahuja1993,
  author     = {Ahuja, N. and Abbott, A.L.},
  journal    = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title      = {Active stereo: integrating disparity, vergence, focus, aperture and calibration for surface estimation},
  year       = {1993},
  issn       = {1939-3539},
  month      = oct,
  number     = {10},
  pages      = {1007--1029},
  volume     = {15},
  abstract   = {An approach to integrating stereo disparity, camera vergence, and lens focus to exploit their complementary strengths and weaknesses through active control of camera focus and orientations is presented. In addition, the aperture and zoom settings of the cameras are controlled. The result is an active vision system that dynamically and cooperatively interleaves image acquisition with surface estimation. A dense composite map of a single contiguous surface is synthesized by automatically scanning the surface and combining estimates of adjacent, local surface patches. This problem is formulated as one of minimizing a pair of objective functions. The first such function is concerned with the selection of a target for fixation. The second objective function guides the surface estimation process in the vicinity of the fixation point. Calibration parameters of the cameras are treated as variables during optimization, thus making camera calibration an integral, flexible component of surface estimation. An implementation of this method is described, and a performance evaluation of the system is presented. An average absolute error of less than 0.15\% in estimated depth was achieved for a large surface having a depth of approximately 2 m.{\textless}{\textgreater}},
  doi        = {10.1109/34.254059},
  file       = {IEEE Xplore Full Text PDF:Ahuja1993 - Active Stereo_ Integrating Disparity, Vergence, Focus, Aperture and Calibration for Surface Estimation.html:URL:https\://ieeexplore-ieee-org.eaccess.tum.edu/stampPDF/getPDF.jsp?tp=&arnumber=254059&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2Fic3RyYWN0L2RvY3VtZW50LzI1NDA1OQ==},
  keywords   = {Apertures, Calibration, Cameras, Surface reconstruction, Image reconstruction, Layout, Focusing, Surface treatment, Automatic control, Lenses},
  shorttitle = {Active stereo},
  url        = {https://ieeexplore-ieee-org.eaccess.tum.edu/abstract/document/254059},
  urldate    = {2024-06-03},
}

@Misc{,
  title      = {A survey on real-time 3D scene reconstruction with SLAM methods in embedded systems},
  accessdate = {2024-06-07},
  file       = {:- 2309.05349v1.pdf:PDF:https\://arxiv.org/pdf/2309.05349},
  groups     = {Underwater 3D Reconstruction},
  ranking    = {rank5},
  readstatus = {read},
  url        = {https://arxiv.org/pdf/2309.05349},
}

@Misc{,
  author     = {Tim Dolereit},
  title      = {Concepts for Underwater Stereo Calibration, Stereo 3D-Reconstruction and Evaluation},
  accessdate = {2024-06-07},
  file       = {:- N 374915.pdf:PDF:https\://publica-rest.fraunhofer.de/server/api/core/bitstreams/d1ea460f-2bc1-4932-a9f3-46e6e6d4286b/content},
  groups     = {Camera Calibration},
  ranking    = {rank2},
  url        = {https://publica-rest.fraunhofer.de/server/api/core/bitstreams/d1ea460f-2bc1-4932-a9f3-46e6e6d4286b/content},
}

@Misc{,
  author     = {Mengkun She, Yifan Song, Jochen Mohrmann, and Kevin Koeser},
  title      = {Adjustment and Calibration of Dome Port Camera Systems for Underwater Vision},
  abstract   = {Abstract. Handling refractive effects in computer vision disciplines like
underwater stereo camera system calibration or 3D-reconstruction is a
major challenge. Refraction occurs at the borders between different me-
dia on the way of the light and introduces non-linear distortions, that are
dependent on the imaged scene. In this paper, concepts will be proposed
for the calibration of a stereo camera system including a set of additional
refractive parameters, for underwater stereo 3D-reconstruction and for
evaluation of the computations.},
  accessdate = {2024-06-07},
  file       = {:- Domecalibration_preprint.pdf:PDF:https\://www.geomar.de/fileadmin/personal/fb2/mg/kkoeser/domecalibration_preprint.pdf},
  groups     = {Camera Calibration},
  ranking    = {rank5},
  readstatus = {read},
  url        = {https://www.geomar.de/fileadmin/personal/fb2/mg/kkoeser/domecalibration_preprint.pdf},
}

@misc{,		title={An_Introduction_to_Sensor_Fusion},		file={:https\://www.researchgate.net/profile/Wilfried-Elmenreich/publication/267771481_An_Introduction_to_Sensor_Fusion/links/55d2e45908ae0a3417222dd9/An-Introduction-to-Sensor-Fusion.pdf:PDF},		url = {https://www.researchgate.net/profile/Wilfried-Elmenreich/publication/267771481_An_Introduction_to_Sensor_Fusion/links/55d2e45908ae0a3417222dd9/An-Introduction-to-Sensor-Fusion.pdf},		accessDate={2024-06-20},		}

@Article{Shortis2015,
  author    = {Shortis, Mark},
  journal   = {Sensors},
  title     = {Calibration Techniques for Accurate Measurements by Underwater Camera Systems},
  year      = {2015},
  issn      = {1424-8220},
  month     = dec,
  number    = {12},
  pages     = {30810--30826},
  volume    = {15},
  doi       = {10.3390/s151229831},
  groups    = {Underwater Environment, Camera Calibration},
  publisher = {MDPI AG},
  ranking   = {rank4},
}

@Article{MassotCampos2015,
  author    = {Massot-Campos, Miquel and Oliver-Codina, Gabriel},
  journal   = {Sensors},
  title     = {Optical Sensors and Methods for Underwater 3D Reconstruction},
  year      = {2015},
  issn      = {1424-8220},
  month     = dec,
  number    = {12},
  pages     = {31525--31557},
  volume    = {15},
  doi       = {10.3390/s151229864},
  groups    = {Underwater 3D Reconstruction, 3D Reconstruction},
  priority  = {prio1},
  publisher = {MDPI AG},
}

@Article{Millane2023,
  author        = {Millane, Alexander and Oleynikova, Helen and Wirbel, Emilie and Steiner, Remo and Ramasamy, Vikram and Tingdahl, David and Siegwart, Roland},
  title         = {nvblox: GPU-Accelerated Incremental Signed Distance Field Mapping},
  year          = {2023},
  month         = nov,
  abstract      = {Dense, volumetric maps are essential to enable robot navigation and interaction with the environment. To achieve low latency, dense maps are typically computed onboard the robot, often on computationally constrained hardware. Previous works leave a gap between CPU-based systems for robotic mapping which, due to computation constraints, limit map resolution or scale, and GPU-based reconstruction systems which omit features that are critical to robotic path planning, such as computation of the Euclidean Signed Distance Field (ESDF). We introduce a library, nvblox, that aims to fill this gap, by GPU-accelerating robotic volumetric mapping. Nvblox delivers a significant performance improvement over the state of the art, achieving up to a 177x speed-up in surface reconstruction, and up to a 31x improvement in distance field computation, and is available open-source.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2311.00626},
  eprint        = {2311.00626},
  file          = {:Millane2023 - Nvblox_ GPU Accelerated Incremental Signed Distance Field Mapping.pdf:PDF:http\://arxiv.org/pdf/2311.00626v2},
  groups        = {3D Reconstruction},
  keywords      = {Robotics (cs.RO), FOS: Computer and information sciences},
  primaryclass  = {cs.RO},
  priority      = {prio1},
  publisher     = {arXiv},
}

@Article{Hornung2013,
  author    = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
  journal   = {Autonomous Robots},
  title     = {OctoMap: an efficient probabilistic 3D mapping framework based on octrees},
  year      = {2013},
  issn      = {1573-7527},
  month     = feb,
  number    = {3},
  pages     = {189--206},
  volume    = {34},
  doi       = {10.1007/s10514-012-9321-0},
  groups    = {3D Reconstruction},
  publisher = {Springer Science and Business Media LLC},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Depth Maps\;0\;1\;\;\;\;;
1 StaticGroup:Underwater 3D Reconstruction\;0\;1\;\;\;\;;
1 StaticGroup:Underwater Environment\;0\;1\;\;\;\;;
1 StaticGroup:Hardware\;0\;1\;\;\;\;;
1 StaticGroup:3D Reconstruction\;0\;1\;\;\;\;;
1 StaticGroup:Camera Calibration\;0\;1\;\;\;\;;
}
